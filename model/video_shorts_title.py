from moviepy.editor import VideoFileClip, AudioFileClip
from PIL import ImageFont
import torch
from transformers import AutoImageProcessor, AutoModelForVideoClassification
import cv2
import os
import json
import random
import numpy as np
from PIL import ImageDraw, Image

### ê²½ë¡œ ì„¤ì • ###
BASE_PATH = '/home/aikusrv02/aiku/video_retrieval'
font_path = '/home/aikusrv02/aiku/video_retrieval/data/á„‹á…µá„‰á…¥á„‹á…²á†«á„á…¦.ttf'
base_data_path = f"{BASE_PATH}/data/home_alone"

def extract_frames(video_path, num_frames=16):
    """ë¹„ë””ì˜¤ì—ì„œ ê· ì¼í•œ ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ì¶”ì¶œ ë° ë¦¬ì‚¬ì´ì¦ˆ"""
    frames = []
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        print(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return None
        
    interval = max(total_frames // num_frames, 1)
    target_size = (224, 224)  # VideoMAE ëª¨ë¸ì˜ ê¸°ëŒ€ ì…ë ¥ í¬ê¸°
    
    try:
        for i in range(num_frames):
            frame_idx = min(i * interval, total_frames - 1)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            
            if not ret:
                print(f"í”„ë ˆì„ {frame_idx} ì½ê¸° ì‹¤íŒ¨")
                continue
                
            # í”„ë ˆì„ ì „ì²˜ë¦¬
            frame = cv2.resize(frame, target_size)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame)
            
    except Exception as e:
        print(f"í”„ë ˆì„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        cap.release()
    
    if len(frames) != num_frames:
        print(f"ì¶”ì¶œëœ í”„ë ˆì„ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì˜ˆìƒ: {num_frames}, ì‹¤ì œ: {len(frames)})")
        return None
        
    return np.array(frames)  # numpy ë°°ì—´ë¡œ ë³€í™˜

def analyze_video_content(video_path):
    """ë¹„ë””ì˜¤ ë‚´ìš© ë¶„ì„í•˜ì—¬ í–‰ë™/ì¥ë©´ ì„¤ëª… ìƒì„±"""
    try:
        processor = AutoImageProcessor.from_pretrained("MCG-NJU/videomae-base-finetuned-kinetics")
        model = AutoModelForVideoClassification.from_pretrained("MCG-NJU/videomae-base-finetuned-kinetics")
        
        frames = extract_frames(video_path)
        if frames is None:
            print("í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨")
            return None
            
        try:
            # ì…ë ¥ í˜•íƒœ í™•ì¸ ë° ì¶œë ¥
            print(f"í”„ë ˆì„ ë°°ì—´ í˜•íƒœ: {frames.shape}")
            
            # í”„ë ˆì„ ì •ê·œí™” ë° ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
            inputs = processor(list(frames), return_tensors="pt")
            
            with torch.no_grad():
                outputs = model(**inputs)
                logits = outputs.logits
                top_k = 3
                topk_values, topk_indices = torch.topk(logits, top_k)
                predictions = []
                
                for idx in topk_indices[0]:
                    label = model.config.id2label[idx.item()]
                    predictions.append(label)
            
            return predictions
            
        except Exception as e:
            print(f"ëª¨ë¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"ì…ë ¥ í…ì„œ í¬ê¸°: {inputs['pixel_values'].shape}")  # ë””ë²„ê¹…ìš©
            return None
        
    except Exception as e:
        print(f"ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def generate_shorts_title(actions):
    """ì‡¼ì¸  ìŠ¤íƒ€ì¼ì˜ ë§¤ë ¥ì ì¸ í•œê¸€ ì œëª© ìƒì„±"""
    
    # í–‰ë™ í•œê¸€ ë§¤í•‘ (ë” ê°ê°ì ì¸ í‘œí˜„ìœ¼ë¡œ ìˆ˜ì •)
    action_mapping = {
        'fighting': 'ê²©íŒŒ',
        'running': 'ë„ì£¼',
        'falling': 'ë‚™ì‚¬',
        'laughing': 'ë¹µí„°ì§„',
        'screaming': 'ì ˆê·œí•˜ëŠ”',
        'dancing': 'ì¶¤ì¶”ëŠ”',
        'jumping': 'ì í”„',
        'eating': 'ë¨¹ë°©',
        'playing': 'í”Œë ˆì´',
        'hitting': 'ê²©íŒŒ',
        'throwing': 'ë˜ì§€ê¸°',
        'catching': 'ìºì¹˜',
        'sliding': 'ìŠ¬ë¼ì´ë”©',
        'hiding': 'ìŠ¤í…”ìŠ¤',
        'chasing': 'ì¶”ê²©',
        'pranking': 'ëª°ì¹´',
        'surprising': 'ì¶©ê²©ì ',
        'tricking': 'ì†ì„ìˆ˜'
    }
    
    # ì‡¼ì¸  ìŠ¤íƒ€ì¼ ì´ëª¨ì§€
    emoji_mapping = {
        'fighting': ['ğŸ”¥', 'ğŸ‘Š'],
        'running': ['ğŸ’¨', 'ğŸƒ'],
        'falling': ['ğŸ’«', 'ğŸ˜±'],
        'laughing': ['ğŸ¤£', 'ğŸ˜‚'],
        'screaming': ['ğŸ˜±', 'âš¡'],
        'dancing': ['ğŸ•º', 'ğŸ’ƒ'],
        'jumping': ['â¬†ï¸', 'ğŸ¦˜'],
        'eating': ['ğŸ½ï¸', 'ğŸ˜‹'],
        'playing': ['ğŸ®', 'ğŸ¯'],
        'hitting': ['ğŸ’¥', 'ğŸ‘Š'],
        'throwing': ['ğŸ¯', 'ğŸª'],
        'catching': ['ğŸ¯', 'ğŸ™Œ'],
        'sliding': ['ğŸ’¨', 'ğŸŒªï¸'],
        'hiding': ['ğŸ™ˆ', 'ğŸ‘»'],
        'chasing': ['ğŸƒ', 'ğŸ’¨'],
        'pranking': ['ğŸ˜ˆ', 'ğŸ­'],
        'surprising': ['ğŸ˜²', 'â—'],
        'tricking': ['ğŸ­', 'ğŸƒ']
    }
    
    main_action = actions[0].lower()
    emoji = random.choice(emoji_mapping.get(main_action, ['âœ¨', 'ğŸ”¥']))
    
    # ì‡¼ì¸  ìŠ¤íƒ€ì¼ ì œëª© í…œí”Œë¦¿
    templates = [
        # ê¶ê¸ˆì¦ ìœ ë°œí˜•
        [
            f"ì¼€ë¹ˆì´ {action_mapping.get(main_action, 'ë¯¸ì³¤ë‹¤')}.. {emoji}",
            f"ì´ê²Œ ë˜ë„¤?! {action_mapping.get(main_action, 'ì²œì¬')} ì¼€ë¹ˆ {emoji}",
            f"ë„ë‘‘ë“¤ ì‹¤ì œ ë°˜ì‘ {emoji} (ft. {action_mapping.get(main_action, 'ì¶©ê²©')})",
        ],
        
        # ì„íŒ©íŠ¸í˜•
        [
            f"ì—­ëŒ€ê¸‰ {action_mapping.get(main_action, 'ë ˆì „ë“œ')} ìˆœê°„ {emoji}",
            f"ì¼€ë¹ˆ ë§¤ìš´ë§› {action_mapping.get(main_action, 'ë³µìˆ˜')} {emoji}",
            f"ì´ ì¥ë©´ ì‹¤í™”ì„ {emoji} {action_mapping.get(main_action, 'ì¶©ê²©')}",
        ],
        
        # ë°ˆí˜•
        [
            f"ì´ë•Œë¶€í„° ì „ì„¤ì´ì—ˆë‹¤ {emoji} #{action_mapping.get(main_action, 'ë ˆì „ë“œ')}",
            f"ì¼€ë¹ˆ ì§„ì§œ ë¬´ì„­ë„¤ {emoji} #{action_mapping.get(main_action, 'ì‹¤í™”')}",
            f"ë„ë‘‘ë“¤ ë©˜íƒˆ ë¶•ê´´ {emoji} #{action_mapping.get(main_action, 'íŒŒê´´')}",
        ]
    ]
    
    # ëœë¤ ì„ íƒ + í•´ì‹œíƒœê·¸ ì¶”ê°€
    category = random.choice(templates)
    title = random.choice(category)
    
    # 50% í™•ë¥ ë¡œ íŠ¸ë Œë””í•œ í•´ì‹œíƒœê·¸ ì¶”ê°€
    if random.random() < 0.5:
        hashtags = ["#í™ˆì–¼ë¡ ", "#ë‚˜í™€ë¡œì§‘ì—", "#ì¼€ë¹ˆ", "#ì¶”ì–µì˜ëª…ì¥ë©´", "#ë ˆì „ë“œ"]
        title += f" {random.choice(hashtags)}"
    
    return title

def generate_thumbnail_text(title):
    """ì¸ë„¤ì¼ìš© ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    # ì´ëª¨ì§€ì™€ í•´ì‹œíƒœê·¸ ì œê±°
    clean_title = ''.join(char for char in title if not char in 'ğŸ”¥ğŸ‘ŠğŸ’¨ğŸƒğŸ˜±ğŸ¤£ğŸ˜‚âš¡ğŸ•ºğŸ’ƒâ¬†ï¸ğŸ¦˜ğŸ½ï¸ğŸ˜‹ğŸ®ğŸ¯ğŸ’¥ğŸ‘ŠğŸªğŸ™ŒğŸŒªï¸ğŸ‘»ğŸ˜ˆğŸ­ğŸ˜²â—ğŸƒâœ¨ #')
    
    # ê¸´ ì œëª©ì€ ì²« ë¶€ë¶„ë§Œ ì‚¬ìš©
    if len(clean_title) > 15:
        clean_title = clean_title[:15] + '...'
    
    return clean_title.strip()
'''
def find_korean_font():
    """SSH í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ì°¾ê¸°"""
    # ì„œë²„ í™˜ê²½ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” í°íŠ¸ ê²½ë¡œë“¤
    font_paths = [
        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
        '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf',
        '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc',
        '/usr/share/fonts/noto-cjk/NotoSansCJK-Regular.ttc',
        '/usr/share/fonts/truetype/unfonts-core/UnDotum.ttf',
        '/usr/share/fonts/truetype/fonts-korean-gothic/gothic.ttf'
    ]
    
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                # í°íŠ¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
                font = ImageFont.truetype(font_path, 14)
                print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ë°œê²¬: {font_path}")
                return font_path
            except Exception as e:
                continue
    
    # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ í°íŠ¸ ì°¾ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    font_dir = os.path.join(current_dir, 'fonts')
    
    if os.path.exists(font_dir):
        for file in os.listdir(font_dir):
            if file.endswith(('.ttf', '.otf')):
                font_path = os.path.join(font_dir, file)
                try:
                    font = ImageFont.truetype(font_path, 14)
                    print(f"ë¡œì»¬ í°íŠ¸ ë°œê²¬: {font_path}")
                    return font_path
                except:
                    continue
    
    print("ê²½ê³ : í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í°íŠ¸ ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë‚˜ëˆ”í°íŠ¸ë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("sudo apt-get install fonts-nanum")
    return None
'''

def add_title_to_video(video_path, title, output_path):
    """OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ì— ì œëª© ì˜¤ë²„ë ˆì´ ì¶”ê°€í•˜ê³  ì˜¤ë””ì˜¤ ê²°í•©"""
    try:
        # ë¹„ë””ì˜¤ ì½ê¸°
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        # ë¹„ë””ì˜¤ ì†ì„± ê°€ì ¸ì˜¤ê¸°
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        temp_output_path = output_path.replace('.mp4', '_temp.mp4')
        out = cv2.VideoWriter(temp_output_path, fourcc, fps, (width, height))

        # í°íŠ¸ ì„¤ì •
        font_size = int(width / 15)
        font = ImageFont.truetype(font_path, font_size)

        # ì²« í•´ì‹œíƒœê·¸ì—ì„œ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
        if "#" in title:
            split_pos = title.index("#")
            title_lines = [title[:split_pos].strip(), title[split_pos:].strip()]
        else:
            title_lines = [title]

        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ë¥¼ í™”ë©´ì˜ ì•„ë˜ìª½ìœ¼ë¡œ ì¡°ì •
        y_offset = int(height * 0.75)

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # OpenCV í”„ë ˆì„ì„ PIL Imageë¡œ ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(frame_rgb)
            draw = ImageDraw.Draw(pil_img)

            for i, line in enumerate(title_lines):
                # ê° ì¤„ì˜ ë„ˆë¹„ ê³„ì‚°
                line_bbox = draw.textbbox((0, 0), line, font=font)
                line_width = line_bbox[2] - line_bbox[0]
                x_pos = (width - line_width) // 2
                y_pos = y_offset + (i * (font_size + 10))  # ì¤„ ê°„ê²© 10í”½ì…€

                # í…ìŠ¤íŠ¸ ê·¸ë¦¼ì íš¨ê³¼
                shadow_color = (0, 0, 0)
                shadow_offset = int(font_size * 0.05)

                # ì „ë°©í–¥ ê·¸ë¦¼ìë¡œ ë” êµµì€ ì™¸ê³½ì„  íš¨ê³¼
                for dx in range(-shadow_offset, shadow_offset + 1, 2):
                    for dy in range(-shadow_offset, shadow_offset + 1, 2):
                        draw.text((x_pos + dx, y_pos + dy), line, font=font, fill=shadow_color)

                # ë©”ì¸ í…ìŠ¤íŠ¸ (í°ìƒ‰) - í•´ì‹œíƒœê·¸ì™€ ì´ëª¨ì§€ í¬í•¨
                draw.text((x_pos, y_pos), line, font=font, fill=(255, 255, 255))

            # PIL Imageë¥¼ ë‹¤ì‹œ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            out.write(frame)

            # ì§„í–‰ë¥  í‘œì‹œ
            current_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)
            progress = int((current_frame / total_frames) * 100)
            if progress % 10 == 0:
                print(f"ì²˜ë¦¬ ì§„í–‰ë¥ : {progress}%")

        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        cap.release()
        out.release()

        # MoviePyë¡œ ë¹„ë””ì˜¤ì— ì›ë³¸ ì˜¤ë””ì˜¤ ì¶”ê°€
        video_with_audio = VideoFileClip(temp_output_path)
        original_audio = VideoFileClip(video_path).audio
        final_video = video_with_audio.set_audio(original_audio)
        final_video.write_videofile(output_path, codec="libx264", audio_codec="aac")

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_output_path)

        print("ì œëª© ì¶”ê°€ ë° ì˜¤ë””ì˜¤ ìœ ì§€ ì™„ë£Œ")
        return True

    except Exception as e:
        print(f"ë¹„ë””ì˜¤ ì œëª© ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def save_video_metadata(video_path, title, actions, output_dir):
    """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        video = VideoFileClip(video_path)
        metadata = {
            'video_path': video_path,
            'title': title,
            'actions': actions,
            'duration': video.duration
        }
        video.close()
        
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        json_path = os.path.join(output_dir, f"{base_name}_metadata.json")
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=4)
            
        return True
    except Exception as e:
        print(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

if __name__ == "__main__":
    print("í”„ë¡œê·¸ë¨ ì‹œì‘")  # ë””ë²„ê¹…ìš© print
    
    # ì…ë ¥/ì¶œë ¥ ê²½ë¡œ ì„¤ì •
    final_video_path = f"{base_data_path}/shorts_trimmed/"
    metadata_dir = f"{base_data_path}/shorts_metadata/"
    
    # ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(metadata_dir, exist_ok=True)
    
    # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(final_video_path):
        print(f"ì˜¤ë¥˜: ì…ë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {final_video_path}")
        exit(1)
    
    # ì²˜ë¦¬í•  ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡
    video_files = [f for f in os.listdir(final_video_path) if f.endswith('.mp4')]
    print(f"ë°œê²¬ëœ ë¹„ë””ì˜¤ íŒŒì¼ë“¤: {video_files}")  # ë””ë²„ê¹…ìš© print
    
    if not video_files:
        print(f"ì˜¤ë¥˜: ì…ë ¥ ë””ë ‰í† ë¦¬ì— MP4 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {final_video_path}")
        exit(1)
    
    print(f"ì²˜ë¦¬í•  ë¹„ë””ì˜¤ íŒŒì¼ ìˆ˜: {len(video_files)}")
    
    for file in video_files:
        video_path = os.path.join(final_video_path, file)
        print(f"\nì²˜ë¦¬ ì¤‘ì¸ íŒŒï¿½ï¿½: {file}")
        
        # 1. ë¹„ë””ì˜¤ ë‚´ìš© ë¶„ì„
        actions = analyze_video_content(video_path)
        
        if actions:
            # 2. ì œëª© ìƒì„±
            title = generate_shorts_title(actions)
            thumbnail_text = generate_thumbnail_text(title)
            
            # 3. ì œëª©ì´ ìˆëŠ” ë¹„ë””ì˜¤ ìƒì„±
            output_video_path = os.path.join(
                metadata_dir,
                f"titled_{os.path.basename(video_path)}"
            )
            
            if add_title_to_video(video_path, title, output_video_path):
                print(f"ì œëª©ì´ ì¶”ê°€ëœ ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_video_path}")
            else:
                print("ì œëª© ì¶”ê°€ ì‹¤íŒ¨")
            
            # 4. ë©”íƒ€ë°ì´í„° ì €ì¥
            if save_video_metadata(video_path, title, actions, metadata_dir):
                print(f"ìƒì„±ëœ ì œëª©: {title}")
                print(f"ì¸ë„¤ì¼ í…ìŠ¤íŠ¸: {thumbnail_text}")
                print(f"ê°ì§€ëœ í–‰ë™: {', '.join(actions)}")
                print(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            else:
                print("ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
        else:
            print(f"ë¹„ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨")
        
        print("-" * 50)
    
    print("\nëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")